{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "eRtRshMosUTw",
        "outputId": "bf4e1704-fde0-4018-e4f0-e2f70faf9554"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'tuple'>\n",
            "['ODD' 'ODD' 'ODD' ... 'EVEN' 'ODD' 'EVEN']\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import sys\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "num_train = 2000\n",
        "image_train = []\n",
        "for i in range(num_train):\n",
        "    image = cv2.imread(\"/Users/himeshagrawal/Downloads/assn2 2/train/%d.png\" % i)\n",
        "    image_train.append(image)\n",
        "\n",
        "file = open( \"/Users/himeshagrawal/Downloads/assn2 2/train/labels.txt\", \"r\" )\n",
        "label_train = file.read().splitlines()\n",
        "file.close()\n",
        "label_train = np.array(label_train)\n",
        "image_train = np.array(image_train)\n",
        "print(type(image_train.shape))\n",
        "print(label_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_lines(img):\n",
        "  _, binary = cv2.threshold(img, 210, 255, cv2.THRESH_BINARY)\n",
        "  kernels = np.ones((5,5), np.uint8)\n",
        "  dilated = cv2.dilate(binary, kernels, iterations=1)\n",
        "  return dilated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pre_processing(image):\n",
        "    cv2.imwrite(f'/Users/himeshagrawal/Downloads/assn2 2/images/final0.png',image)\n",
        "    top_left = (0, 0)\n",
        "    top_right = (image.shape[0]-1, 0)\n",
        "    bottom_left = (0, image.shape[1]-1)\n",
        "    bottom_right = (image.shape[0]-1, image.shape[1]-1)\n",
        "    \n",
        "    color_frequencies = {}\n",
        "    for corner in [top_left, top_right, bottom_left, bottom_right]:\n",
        "        color = image[corner]\n",
        "        color_tup = tuple(color)\n",
        "        if color_tup not in color_frequencies:\n",
        "           color_frequencies[color_tup] = 0\n",
        "        color_frequencies[color_tup] += 1\n",
        "\n",
        "    max_color = max(color_frequencies, key=color_frequencies.get)\n",
        "    R = max_color[0]\n",
        "    G = max_color[1]\n",
        "    B = max_color[2]\n",
        "\n",
        "    h,w,c = image.shape\n",
        "    for i in range(h):\n",
        "        for j in range(w):\n",
        "           if R == image[i,j,0] and G == image[i,j,1] and B == image[i,j,2]:\n",
        "            image[i,j,0] = 255\n",
        "            image[i,j,1] = 255\n",
        "            image[i,j,2] = 255\n",
        "\n",
        "    cv2.imwrite(f'/Users/himeshagrawal/Downloads/assn2 2/images/final1.png',image)\n",
        "    img2 = image\n",
        "    image_rgb = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
        "    pixels = image_rgb.reshape(-1, 3)\n",
        "    non_white_pixels = [pixel for pixel in pixels if not np.array_equal(pixel, [255, 255, 255])]\n",
        "    color_counts = Counter(map(tuple, non_white_pixels))\n",
        "    most_common_color = color_counts.most_common(1)[0][0]\n",
        "    print(most_common_color)\n",
        "    R = most_common_color[0]\n",
        "    G = most_common_color[1]\n",
        "    B = most_common_color[2]\n",
        "    img2 = image_rgb\n",
        "    h,w,c = img2.shape\n",
        "    for i in range(h):\n",
        "        for j in range(w):\n",
        "            if R!= img2[i,j,0]:\n",
        "                img2[i,j,0] = 255\n",
        "                img2[i,j,1] = 255\n",
        "                img2[i,j,2] = 255\n",
        "            if G != img2[i,j,1]:\n",
        "                img2[i,j,0] = 255\n",
        "                img2[i,j,1] = 255\n",
        "                img2[i,j,2] = 255\n",
        "            if B != img2[i,j,2]:\n",
        "                img2[i,j,0] = 255\n",
        "                img2[i,j,1] = 255\n",
        "                img2[i,j,2] = 255\n",
        "\n",
        "    cv2.imwrite(f'/Users/himeshagrawal/Downloads/assn2 2/images/final3.png',img2)\n",
        "    return img2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(255, 130, 128)\n",
            "0\n",
            "(140, 255, 128)\n",
            "1\n",
            "(159, 255, 128)\n",
            "2\n",
            "(128, 0, 0)\n",
            "3\n",
            "(255, 138, 128)\n",
            "4\n",
            "(128, 130, 255)\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "p4 = np.zeros((2000,100,100,3))\n",
        "for i in range(6):\n",
        "    p4[i] = pre_processing(image_train[i][:,350:450,:])\n",
        "    cv2.imwrite(f'/Users/himeshagrawal/Downloads/assn2 2/images/final5.png', p4[i])\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Convert string labels to numerical labels\n",
        "# train_labels = [0 if label == 'ODD' else 1 for label in label_train]\n",
        "\n",
        "# train_labels = np.array(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_ref = 16\n",
        "image_ref = []\n",
        "label_ref = ['0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F']\n",
        "for i in range(num_ref):\n",
        "    image = cv2.imread(\"/Users/himeshagrawal/Downloads/assn2 2/reference/%c.png\" % label_ref[i])\n",
        "    image_ref.append(image)\n",
        "\n",
        "\n",
        "lable_ref = np.array(label_ref)\n",
        "image_ref = np.array(image_ref)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(16, 100, 100, 3)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_ref.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_test = 7\n",
        "image_test = []\n",
        "for i in range(num_test):\n",
        "    image = cv2.imread(\"/Users/himeshagrawal/Downloads/assn2 2/dummy_submit/test/%d.png\" % i)\n",
        "    image_test.append(image)\n",
        "\n",
        "file = open( \"/Users/himeshagrawal/Downloads/assn2 2/dummy_submit/model.txt\", \"r\" )\n",
        "label_test = file.read().splitlines()\n",
        "file.close()\n",
        "label_test = np.array(label_test)\n",
        "image_test = np.array(image_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "p1_test = np.zeros((7,100,125,3))\n",
        "p2_test = np.zeros((7,100,125,3))\n",
        "p3_test = np.zeros((7,100,125,3))\n",
        "p4_test = np.zeros((7,100,125,3))\n",
        "for i in range(7):\n",
        "    image_test[i] = pre_processing(image_test[i])\n",
        "    p1_test[i],p2_test[i],p3_test[i],p4_test[i] = segement(image_test[i])\n",
        "    print(i)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert string labels to numerical labels\n",
        "# test_labels = [0 if label == 'ODD' else 1 for label in label_test]\n",
        "# test_labels = np.array(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "data_dir = '/Users/himeshagrawal/Downloads/assn2 2/seg_image'\n",
        "\n",
        "image_size = (100, 100)\n",
        "# Load the images and convert them to grayscale\n",
        "images = []\n",
        "for i in range(2000):\n",
        "    image_path = os.path.join(data_dir, str(i) + \".png\")\n",
        "    image = Image.open(image_path).convert(\"L\")\n",
        "    image = np.array(image.resize(image_size)).flatten()  # Resize to specified size and flatten\n",
        "    images.append(image)\n",
        "\n",
        "# Step 2: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, label_train, test_size=0.1, random_state=42)\n",
        "\n",
        "\n",
        "# # Step 4: Make predictions on the testing set\n",
        "# y_pred = clf.predict(X_test)\n",
        "\n",
        "# # Step 5: Evaluate the model\n",
        "# accuracy = accuracy_score(y_test,y_pred)\n",
        "# print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        EVEN       1.00      1.00      1.00       112\n",
            "         ODD       1.00      1.00      1.00        88\n",
            "\n",
            "    accuracy                           1.00       200\n",
            "   macro avg       1.00      1.00      1.00       200\n",
            "weighted avg       1.00      1.00      1.00       200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "k = 5  # Number of neighbors\n",
        "knn = KNeighborsClassifier(n_neighbors=k)\n",
        "knn.fit(X_train,y_train)\n",
        "\n",
        "# Step 4: Predict the labels for the test set\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Step 5: Evaluate the accuracy of the classifier\n",
        "accuracy = classification_report(y_test, y_pred)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        EVEN       0.97      0.98      0.98       112\n",
            "         ODD       0.98      0.97      0.97        88\n",
            "\n",
            "    accuracy                           0.97       200\n",
            "   macro avg       0.98      0.97      0.97       200\n",
            "weighted avg       0.98      0.97      0.97       200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Initialize the decision tree classifier\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "# # Define the parameter grid for fine-tuning\n",
        "# param_grid = {\n",
        "#     'max_depth': [3, 5, 7],\n",
        "#     'min_samples_split': [2, 5, 10],\n",
        "#     'min_samples_leaf': [1, 3, 5],\n",
        "# }\n",
        "\n",
        "# # Perform grid search with cross-validation\n",
        "# grid_search = GridSearchCV(dt, param_grid, cv=5)\n",
        "# grid_search.fit(X_train, y_train)\n",
        "\n",
        "# # Get the best model and its parameters\n",
        "# best_model = grid_search.best_estimator_\n",
        "# best_params = grid_search.best_params_\n",
        "\n",
        "# Train the decision tree classifier with the best parameters\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = classification_report(y_test, y_pred)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
          ]
        }
      ],
      "source": [
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        EVEN       1.00      1.00      1.00       112\n",
            "         ODD       1.00      1.00      1.00        88\n",
            "\n",
            "    accuracy                           1.00       200\n",
            "   macro avg       1.00      1.00      1.00       200\n",
            "weighted avg       1.00      1.00      1.00       200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize the logistic regression classifier\n",
        "lr = LogisticRegression(solver = 'liblinear',penalty = 'l1',max_iter=100)\n",
        "# # Define the parameter grid for fine-tuning\n",
        "# param_grid = {\n",
        "#     'C': [0.1, 1, 10],\n",
        "#     'penalty': ['l1', 'l2'],\n",
        "#     'solver': ['liblinear', 'saga']\n",
        "# }\n",
        "\n",
        "# # # Perform grid search with cross-validation\n",
        "# grid_search = GridSearchCV(lr, param_grid, cv=2)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# # # Get the best model and its parameters\n",
        "# best_model = grid_search.best_estimator_\n",
        "# best_params = grid_search.best_params_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# Calculate the classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "print(classification_rep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file = open( \"/Users/himeshagrawal/Downloads/assn2 2/train/labels.txt\", \"r\" )\n",
        "label_train = file.read().splitlines()\n",
        "file.close()\n",
        "label_train = np.array(label_train)\n",
        "image_train = np.array(image_train)\n",
        "print(type(image_train.shape))\n",
        "print(len(label_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming you have a trained model called \"model\"\n",
        "model = lr  # Your trained model object\n",
        "\n",
        "# Define the file path to store the model\n",
        "model_file = '/Users/himeshagrawal/Downloads/assn2 2/model_l.pkl'\n",
        "\n",
        "# Save the model to a file\n",
        "with open(model_file, 'wb') as file:\n",
        "    pickle.dump(model, file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
